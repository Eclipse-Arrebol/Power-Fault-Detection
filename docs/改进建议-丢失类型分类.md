# 改进"丢失"类型分类效果的方案

## 当前问题分析
- **Precision: 71.86%** - 预测为"丢失"的样本中，只有71.86%是真的丢失（误报率高）
- **Recall: 92.80%** - 能找到92.80%的真实"丢失"样本（漏报率低）
- **结论**: 模型倾向于将其他类型误判为"丢失"

---

## 改进方案

### 方案1: 调整类别权重 ⭐⭐⭐⭐⭐

**原理**: 当前权重可能导致模型过度关注"丢失"类，降低其权重可减少误判

**修改位置**: `train.py` 中所有训练函数的类别权重

```python
# 当前权重
class_weights = torch.tensor([2.0, 50.0, 50.0, 20.0]).to(device)
                            # [正常, 突增, 丢失, 无功]

# 建议调整（降低"丢失"的权重）
class_weights = torch.tensor([2.0, 50.0, 30.0, 20.0]).to(device)
# 或更激进的调整
class_weights = torch.tensor([2.0, 50.0, 20.0, 20.0]).to(device)
```

**优点**: 简单有效，立即见效  
**缺点**: 可能降低 Recall

---

### 方案2: 使用 Focal Loss 参数调整 ⭐⭐⭐⭐

**原理**: 调整 focal_gamma 参数，让模型更关注难分类样本

**修改位置**: `train_causal_gcn_lstm()` 函数

```python
# 当前配置
criterion = create_causal_loss(
    class_weights=class_weights,
    node_depths=node_depths,
    use_focal_loss=True,
    focal_gamma=2.0,  # 调整这个参数
    lambda_root=0.5,
    lambda_sparse=0.01,
    lambda_physics=0.1
)

# 建议调整
focal_gamma=3.0  # 增加到3.0，更关注难样本
# 或
focal_gamma=1.5  # 减少到1.5，平衡各类样本
```

---

### 方案3: 添加后处理阈值调整 ⭐⭐⭐⭐

**原理**: 不直接使用 argmax，而是对"丢失"类设置更高的概率阈值

**实现方式**: 在评估/推理时添加阈值处理

```python
def predict_with_threshold(logits, threshold_dict=None):
    """
    使用自定义阈值进行预测
    
    Args:
        logits: [B, N, C] 模型输出的logits
        threshold_dict: {class_id: threshold} 每个类别的阈值
    """
    if threshold_dict is None:
        threshold_dict = {
            0: 0.5,  # 正常
            1: 0.5,  # 突增
            2: 0.7,  # 丢失 - 提高阈值，减少误判
            3: 0.5   # 无功
        }
    
    probs = torch.softmax(logits, dim=-1)  # [B, N, C]
    pred = logits.argmax(dim=-1)  # 默认预测
    
    # 对"丢失"类设置更高阈值
    class_2_prob = probs[:, :, 2]  # 丢失类的概率
    low_confidence = class_2_prob < threshold_dict[2]
    
    # 如果"丢失"类概率不够高，重新选择次优类别
    probs_copy = probs.clone()
    probs_copy[:, :, 2] = -1  # 屏蔽丢失类
    alternative_pred = probs_copy.argmax(dim=-1)
    
    pred[low_confidence] = alternative_pred[low_confidence]
    
    return pred
```

---

### 方案4: 数据增强和重采样 ⭐⭐⭐

**原理**: 增加"丢失"类样本的多样性，或减少其他类样本

**修改位置**: `src/dataset.py`

```python
def oversample_minority_class(X, Y, target_class=2, factor=1.5):
    """
    对特定类别进行过采样
    """
    class_mask = (Y == target_class).any(dim=1)
    class_samples = X[class_mask]
    class_labels = Y[class_mask]
    
    # 复制样本
    num_copies = int(len(class_samples) * (factor - 1))
    indices = torch.randint(0, len(class_samples), (num_copies,))
    
    X_augmented = torch.cat([X, class_samples[indices]], dim=0)
    Y_augmented = torch.cat([Y, class_labels[indices]], dim=0)
    
    return X_augmented, Y_augmented
```

---

### 方案5: 增强特征表达 ⭐⭐⭐⭐

**原理**: "丢失"可能表现为连续的0值，添加专门的特征提取

**修改位置**: `src/dataset.py` 数据预处理部分

```python
def add_missing_features(data):
    """
    为检测"丢失"添加额外特征
    """
    # 特征1: 连续0值的长度
    zero_mask = (data == 0)
    consecutive_zeros = zero_mask.float()
    
    # 特征2: 与前一时刻的差值（丢失会有突变）
    diff = torch.diff(data, dim=0)
    
    # 特征3: 方差（丢失时方差为0）
    variance = data.var(dim=0, keepdim=True)
    
    return torch.cat([data, consecutive_zeros, diff, variance], dim=-1)
```

---

### 方案6: 两阶段分类 ⭐⭐⭐

**原理**: 先区分"正常 vs 异常"，再对异常进行细分

```python
class TwoStageClassifier(nn.Module):
    def __init__(self, ...):
        super().__init__()
        self.stage1 = ...  # 二分类器：正常 vs 异常
        self.stage2 = ...  # 三分类器：突增 vs 丢失 vs 无功
    
    def forward(self, x):
        # 第一阶段：检测异常
        is_anomaly = self.stage1(x)
        
        # 第二阶段：细分异常类型
        if is_anomaly:
            anomaly_type = self.stage2(x)
            return anomaly_type
        else:
            return 0  # 正常
```

---

## 推荐实施顺序

### 🚀 第一步（最简单）: 调整类别权重
尝试将"丢失"的权重从 50.0 降低到 20.0 ~ 30.0

### 🚀 第二步: 调整 Focal Loss 参数
尝试 gamma = 1.5 或 3.0

### 🚀 第三步: 添加后处理阈值
在推理时对"丢失"类设置 0.7 的概率阈值

### 🚀 第四步（如果前三步效果不佳）: 数据增强
对"丢失"类样本进行特征工程或过采样

---

## 快速测试代码

在 `train.py` 添加以下实验配置：

```python
# ============================================================
# 🔧 实验配置：改进"丢失"类型分类
# ============================================================
LOSS_CLASS_WEIGHTS = {
    'balanced': [2.0, 50.0, 50.0, 20.0],      # 原始权重
    'reduce_missing': [2.0, 50.0, 25.0, 20.0], # 降低丢失权重
    'aggressive': [2.0, 50.0, 15.0, 20.0]      # 激进降低
}

FOCAL_GAMMA_OPTIONS = [1.5, 2.0, 3.0]

# 选择配置
CURRENT_WEIGHTS = LOSS_CLASS_WEIGHTS['reduce_missing']
CURRENT_GAMMA = 2.0
```

---

## 预期效果

| 方案 | Precision 提升 | Recall 变化 | 实施难度 |
|------|---------------|-------------|---------|
| 调整权重 | +5~10% | -2~5% | ⭐ |
| Focal Loss | +3~8% | 持平 | ⭐ |
| 后处理阈值 | +8~15% | -3~8% | ⭐⭐ |
| 数据增强 | +5~12% | +2~5% | ⭐⭐⭐ |
| 特征工程 | +10~20% | +5~10% | ⭐⭐⭐⭐ |

---

## 监控指标

重新训练后，重点关注：
1. **"丢失" Precision** > 85% （目标）
2. **"丢失" Recall** > 90% （保持）
3. **F1-Score** > 87% （综合指标）
4. **混淆矩阵**: 查看哪些类被误判为"丢失"
